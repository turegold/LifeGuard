# FAISS ê²€ìƒ‰ë§Œ í™•ì¸í•˜ëŠ” íŒŒì¼

import os
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ ê³„ì‚°
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
VECTOR_DB_DIR = os.path.join(PROJECT_ROOT, "data", "vectorstore")

# FAISS ë²¡í„° DBì—ì„œ queryì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ kê°œ ê²€ìƒ‰
def search_emergency_guide(query: str, k: int = 3):

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    vectorstore = FAISS.load_local(
        VECTOR_DB_DIR,
        embeddings,
        allow_dangerous_deserialization=True
    )

    docs = vectorstore.similarity_search(query, k=k)

    return docs


if __name__ == "__main__":
    query = "ì‚¬ëŒì´ ê°ì „ëœ ê²ƒ ê°™ê³  ì˜ì‹ì´ ì—†ìŠµë‹ˆë‹¤"

    results = search_emergency_guide(query, k=3)

    print(f"\nğŸ” ì§ˆë¬¸: {query}")
    print("=" * 60)

    for i, doc in enumerate(results, 1):
        print(f"\nğŸ“„ ê²°ê³¼ {i}")
        print(f"ì¶œì²˜: {doc.metadata.get('source')}")
        print("-" * 40)
        print(doc.page_content)